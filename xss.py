import logging
import json
import re
import itertools
import asyncio
import aiohttp
from bs4 import BeautifulSoup
from tenacity import retry, stop_after_attempt, wait_fixed
from aiohttp.client_exceptions import ClientError

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Static Analysis Functions
def find_vulnerable_scripts(html):
    soup = BeautifulSoup(html, 'html.parser')
    scripts = soup.find_all('script')
    vulnerabilities = []

    for script in scripts:
        script_content = script.string
        if script_content:
            if re.search(r'document\.write', script_content) or re.search(r'innerHTML', script_content):
                vulnerabilities.append({
                    'url': 'N/A',
                    'parameter': 'N/A',
                    'payload': script_content.strip(),
                    'method': 'N/A',
                    'vulnerable': True,
                    'is_vulnerable': True,
                    'type': 'Static Analysis',
                    'description': "–ù–∞–π–¥–µ–Ω–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —É—è–∑–≤–∏–º–∞—è JavaScript —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 'document.write' –∏–ª–∏ 'innerHTML'. "
                                   "–≠—Ç–∏ —Ñ—É–Ω–∫—Ü–∏–∏ –º–æ–≥—É—Ç –±—ã—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω–æ–≥–æ –∫–æ–¥–∞, –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø—Ä–æ—Ö–æ–¥—è—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ.",
                    'risk_level': 'üî¥ –í—ã—Å–æ–∫–∏–π',
                    'recommendation': (
                        "–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏–∑–±–µ–≥–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è 'document.write' –∏ 'innerHTML'. "
                        "–í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ DOM, —Ç–∞–∫–∏–µ –∫–∞–∫ 'textContent' –∏–ª–∏ 'innerText'. "
                        "–¢–∞–∫–∂–µ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –¥–∞–Ω–Ω—ã–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –≤ —ç—Ç–∏—Ö —Ñ—É–Ω–∫—Ü–∏—è—Ö, –ø—Ä–æ—Ö–æ–¥—è—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ."
                    )
                })
    return vulnerabilities

# Dynamic Analysis Functions
@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
async def send_request(session, url, method, data=None, headers=None, cookies=None):
    try:
        logger.info(f"Sending {method} request to {url} with data: {data} and headers: {headers}")
        if method == 'GET':
            async with session.get(url, headers=headers, cookies=cookies) as response:
                return await response.text()
        elif method == 'POST':
            async with session.post(url, data=data, headers=headers, cookies=cookies) as response:
                return await response.text()
    except ClientError as e:
        logger.error(f"Request error: {e}")
        raise

async def test_xss_injection(session, url, param, payload, method, headers=None, cookies=None):
    if method == 'GET':
        full_url = f"{url}?{param}={payload}"
        response_text = await send_request(session, full_url, method, headers=headers, cookies=cookies)
    elif method == 'POST':
        data = {param: payload}
        response_text = await send_request(session, url, method, data=data, headers=headers, cookies=cookies)

    if response_text and payload in response_text:
        logger.info(f"XSS vulnerability found with payload: {payload} in {url}")
        return {
            'url': url,
            'parameter': param,
            'payload': payload,
            'method': method,
            'vulnerable': True,
            'is_vulnerable': True,
            'type': 'XSS',
            'description': "–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —É—è–∑–≤–∏–º–æ—Å—Ç—å –º–µ–∂—Å–∞–π—Ç–æ–≤–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∏–Ω–≥–∞ (XSS). "
                           "XSS –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–ª–æ—É–º—ã—à–ª–µ–Ω–Ω–∏–∫—É –≤–Ω–µ–¥—Ä–∏—Ç—å –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã–π —Å–∫—Ä–∏–ø—Ç, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–ø–æ–ª–Ω–∏—Ç—Å—è –≤ –±—Ä–∞—É–∑–µ—Ä–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, "
                           "—á—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –∫—Ä–∞–∂–µ –¥–∞–Ω–Ω—ã—Ö, –ø–æ–¥–¥–µ–ª–∫–µ –∑–∞–ø—Ä–æ—Å–æ–≤ –∏–ª–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–≥–æ –∫–æ–¥–∞.",
            'risk_level': 'üî¥ –í—ã—Å–æ–∫–∏–π',
            'recommendation': (
                "–î–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è XSS –∞—Ç–∞–∫ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:\n"
                "1. –≠–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–¥ –∏—Ö –≤—ã–≤–æ–¥–æ–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É.\n"
                "   –ü—Ä–∏–º–µ—Ä –¥–ª—è Python:\n"
                "   ```python\n"
                "   from markupsafe import escape\n"
                "   safe_input = escape(user_input)\n"
                "   ```\n"
                "2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Content Security Policy (CSP) –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–æ–≤.\n"
                "   –ü—Ä–∏–º–µ—Ä –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ CSP:\n"
                "   ```html\n"
                "   <meta http-equiv=\"Content-Security-Policy\" content=\"default-src 'self'; script-src 'self';\">\n"
                "   ```\n"
                "3. –ü—Ä–æ–≤–µ—Ä—è—Ç—å –∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –≤—Å–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –∏—Å–ø–æ–ª—å–∑—É—è –±–µ–ª—ã–µ —Å–ø–∏—Å–∫–∏ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π.\n"
                "4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –º–∞–Ω–∏–ø—É–ª—è—Ü–∏–∏ DOM, —Ç–∞–∫–∏–µ –∫–∞–∫ 'textContent' –≤–º–µ—Å—Ç–æ 'innerHTML'."
            )
        }
    return {
        'url': url,
        'parameter': param,
        'payload': payload,
        'method': method,
        'vulnerable': False,
        'is_vulnerable': False,
        'type': 'XSS',
        'description': "–£—è–∑–≤–∏–º–æ—Å—Ç—å –º–µ–∂—Å–∞–π—Ç–æ–≤–æ–≥–æ —Å–∫—Ä–∏–ø—Ç–∏–Ω–≥–∞ (XSS) –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞.",
        'risk_level': 'üü¢ –ù–∏–∑–∫–∏–π',
        'recommendation': "–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –≤—Å–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤—Å–µ–≥–¥–∞ –ø—Ä–æ—Ö–æ–¥—è—Ç –≤–∞–ª–∏–¥–∞—Ü–∏—é –∏ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ."
    }

def generate_heuristic_payloads():
    base_payloads = ["<script>alert('XSS')</script>", "<img src=x onerror=alert('XSS')>", "<svg/onload=alert('XSS')>"]
    attributes = ["src", "href", "onload", "onerror", "onclick"]
    events = ["onload", "onerror", "onclick", "onmouseover", "onfocus"]

    heuristic_payloads = base_payloads.copy()
    for attribute, event in itertools.product(attributes, events):
        heuristic_payloads.append(f"<img {attribute}=x {event}=alert('XSS')>")
        heuristic_payloads.append(f"<a {attribute}=x {event}=alert('XSS')>Click me</a>")
    return heuristic_payloads

async def analyze_xss(scraped_data):
    vulnerabilities = []
    logger.info(f"Analyzing XSS vulnerabilities for scraped data: {json.dumps(scraped_data, indent=4)}")
    xss_payloads = {
        "basic": ["<script>alert('XSS')</script>", "<img src=x onerror=alert('XSS')>"],
        "advanced": [
            "<svg/onload=alert('XSS')>",
            "<details/open ontoggle=alert('XSS')>",
            "<a href='javascript:alert(\"XSS\")'>Click me</a>"
        ],
        "dom_based": ["<script>document.body.innerHTML='XSS'</script>"],
        "heuristic": generate_heuristic_payloads()[:5]
    }

    async with aiohttp.ClientSession() as session:
        tasks = []

        for page in scraped_data:
            url = page.get('URL', '')
            if not url:
                logger.error(f"Skipping entry due to missing 'URL' key: {page}")
                continue

            forms = page.get('Forms', [])
            html_content = page.get('HTML Content', '')

            logger.info(f"Processing URL: {url}")
            logger.info(f"Forms: {json.dumps(forms, indent=4)}")
            logger.info(f"HTML Content: {html_content[:200]}...")

            static_vulnerabilities = find_vulnerable_scripts(html_content)
            if static_vulnerabilities:
                vulnerabilities.extend(static_vulnerabilities)

            for form in forms:
                action = form['action'] if form['action'] else url
                method = form['method']
                inputs = form['inputs']
                for input_field in inputs:
                    name = input_field['name']
                    if not name:
                        continue

                    for payload_type, payload_list in xss_payloads.items():
                        for payload in payload_list:
                            tasks.append(
                                test_xss_injection(session, action, name, payload, method)
                            )

            url_params = page.get('Parameters', {})
            for param, value in url_params.items():
                for payload_type, payload_list in xss_payloads.items():
                    for payload in payload_list:
                        tasks.append(
                            test_xss_injection(session, url, param, payload, 'GET')
                        )

            headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"}
            for header in ['User-Agent', 'Referer']:
                for payload_type, payload_list in xss_payloads.items():
                    for payload in payload_list:
                        new_headers = headers.copy()
                        new_headers[header] = payload
                        tasks.append(
                            test_xss_injection(session, url, header, payload, 'GET', new_headers)
                        )

        results = await asyncio.gather(*tasks)
        for result in results:
            if result.get('vulnerable'):
                vulnerabilities.append(result)

    logger.info(f"XSS vulnerabilities found: {json.dumps(vulnerabilities, indent=4)}")
    return vulnerabilities

def load_scraped_data(file_path):
    try:
        with open(file_path, 'r') as file:
            data = json.load(file)
        logger.info(f"Scraped data loaded from {file_path}")
        return data
    except Exception as e:
        logger.error(f"Error loading scraped data from {file_path}: {e}")
        return []

if __name__ == '__main__':
    scraped_data = load_scraped_data('scraped_data.json')
    vulnerabilities = asyncio.run(analyze_xss(scraped_data))
    print("XSS Scan Results:", json.dumps(vulnerabilities, indent=4))
