import logging
import json
import asyncio
import aiohttp
from bs4 import BeautifulSoup

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_csrf(session, url, form):
    form_data = {input['name']: input['value'] for input in form['inputs'] if input['name']}
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    }
    response = await session.post(url, data=form_data, headers=headers)
    logger.info(f"Tested CSRF for URL: {url} - Status Code: {response.status}")
    return response.status != 403

async def analyze_csrf(scraped_data):
    vulnerabilities = []
    async with aiohttp.ClientSession() as session:
        for page in scraped_data:
            url = page['URL']
            forms = page.get('Forms', [])
            logger.info(f"Analyzing URL: {url} - Found Forms: {len(forms)}")
            for form in forms:
                if await test_csrf(session, url, form):
                    form_fields = [input['name'] for input in form['inputs'] if input['name']]
                    vulnerabilities.append({
                        'url': url,
                        'form_action': form['action'],
                        'form_method': form['method'],
                        'form_fields': form_fields,
                        'is_vulnerable': True,
                        'type': 'CSRF',
                        'description': (
                            "CSRF —É—è–∑–≤–∏–º–æ—Å—Ç—å –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–ª–æ—É–º—ã—à–ª–µ–Ω–Ω–∏–∫—É –∑–∞—Å—Ç–∞–≤–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤—ã–ø–æ–ª–Ω–∏—Ç—å "
                            "–Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ –Ω–∞ —Å–∞–π—Ç–µ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ–Ω –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω."
                        ),
                        'risk_level': "üü† –°—Ä–µ–¥–Ω–∏–π",
                        'recommendation': (
                            "–î–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è CSRF –∞—Ç–∞–∫ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:\n"
                            "1. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ CSRF-—Ç–æ–∫–µ–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–π —Ñ–æ—Ä–º—ã.\n"
                            "2. –ü—Ä–æ–≤–µ—Ä—è—Ç—å –Ω–∞–ª–∏—á–∏–µ –∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å CSRF-—Ç–æ–∫–µ–Ω–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–æ—Ä–º—ã –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ.\n"
                            "3. –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –≤—Ä–µ–º—è –∂–∏–∑–Ω–∏ CSRF-—Ç–æ–∫–µ–Ω–∞.\n"
                            "4. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ 'SameSite' –¥–ª—è cookie —Å –∑–Ω–∞—á–µ–Ω–∏–µ–º 'Strict' –∏–ª–∏ 'Lax'.\n"
                            "5. –ü—Ä–æ–≤–µ—Ä—è—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫ –∑–∞–ø—Ä–æ—Å–∞, —Å—Ä–∞–≤–Ω–∏–≤–∞—è –∑–Ω–∞—á–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞ 'Origin' –∏–ª–∏ 'Referer' —Å –¥–æ–≤–µ—Ä–µ–Ω–Ω—ã–º–∏ –¥–æ–º–µ–Ω–∞–º–∏."
                        )
                    })
    return vulnerabilities


def load_scraped_data(file_path):
    try:
        with open(file_path, 'r') as file:
            data = json.load(file)
        logger.info(f"Scraped data loaded from {file_path}")
        return data
    except Exception as e:
        logger.error(f"Error loading scraped data from {file_path}: {e}")
        return []

if __name__ == '__main__':
    scraped_data = load_scraped_data('scraped_data.json')
    vulnerabilities = asyncio.run(analyze_csrf(scraped_data))
    with open('csrf_vulnerabilities.json', 'w') as f:
        json.dump(vulnerabilities, f, indent=4)
    print("CSRF Scan Results:", json.dumps(vulnerabilities, indent=4))
