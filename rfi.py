import asyncio
import aiohttp
import logging
import json

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

async def test_rfi(session, base_url, param):
    rfi_payloads = [
        'https://raw.githubusercontent.com/your-username/your-repo/main/rfi_test.txt',
        'https://raw.githubusercontent.com/m0xvi/web_vuln_scan/master/test/lfi_rfi_test/rfi',
    ]
    for payload in rfi_payloads:
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –ø—Ä–∞–≤–∏–ª—å–Ω–æ, –∑–∞–º–µ–Ω—è—è –∑–Ω–∞—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞
        payloaded_url = f"{base_url.split('?')[0]}?{param}={payload}"
        logger.info(f"Testing RFI with URL: {payloaded_url}")
        try:
            response = await session.get(payloaded_url)
            response_text = await response.text()
            logger.info(f"Response for {payloaded_url}: {response_text[:100]}")  # –õ–æ–≥–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤ –æ—Ç–≤–µ—Ç–∞
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            if 'This is a test file for RFI' in response_text:
                logger.info(f"RFI vulnerability found: {payloaded_url}")
                return True, payloaded_url
        except Exception as e:
            logger.error(f"Error testing RFI payload on {base_url}: {e}")
    return False, None

async def analyze_rfi(scraped_data):
    vulnerabilities = []
    async with aiohttp.ClientSession() as session:
        for page in scraped_data:
            url = page['URL']
            params = page.get('Parameters', {})
            for param in params:
                logger.info(f"Analyzing URL: {url} with param: {param}")
                is_vulnerable, vulnerable_url = await test_rfi(session, url, param)
                if is_vulnerable:
                    vulnerabilities.append({
                        'url': url,
                        'parameter': param,
                        'is_vulnerable': True,
                        'type': 'RFI',
                        'payload': vulnerable_url,
                        'description': (
                            "RFI (Remote File Inclusion) —É—è–∑–≤–∏–º–æ—Å—Ç—å –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–ª–æ—É–º—ã—à–ª–µ–Ω–Ω–∏–∫—É –≤–∫–ª—é—á–∞—Ç—å —É–¥–∞–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ, "
                            "–∏—Å–ø–æ–ª—å–∑—É—è –ø–∞—Ä–∞–º–µ—Ç—Ä—ã URL, —á—Ç–æ –º–æ–∂–µ—Ç –ø—Ä–∏–≤–µ—Å—Ç–∏ –∫ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–≥–æ –∫–æ–¥–∞."
                        ),
                        'risk_level': "üî¥ –í—ã—Å–æ–∫–∏–π",
                        'recommendation': (
                            "–î–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è RFI –∞—Ç–∞–∫ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è:\n"
                            "1. –ü—Ä–æ–≤–µ—Ä—è—Ç—å –∏ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –≤—Å–µ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –∏—Å–∫–ª—é—á–∞—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –ø—É—Ç–µ–π.\n"
                            "2. –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–µ–ª—ã–µ —Å–ø–∏—Å–∫–∏ –¥–æ–ø—É—Å—Ç–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å —Ñ–∞–π–ª–∞–º–∏.\n"
                            "3. –û—Ç–∫–ª—é—á–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏–∏ –≤–∫–ª—é—á–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –∏–∑ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è.\n"
                            "4. –†–µ–≥—É–ª—è—Ä–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å –∏ –ø–∞—Ç—á–∏—Ç—å –ü–û.\n"
                        )
                    })
    return vulnerabilities

def load_scraped_data(file_path):
    try:
        with open(file_path, 'r') as file:
            data = json.load(file)
        logger.info(f"Scraped data loaded from {file_path}")
        return data
    except Exception as e:
        logger.error(f"Error loading scraped data from {file_path}: {e}")
        return []

if __name__ == '__main__':
    scraped_data = load_scraped_data('scraped_data.json')
    vulnerabilities = asyncio.run(analyze_rfi(scraped_data))
    with open('rfi_vulnerabilities.json', 'w') as f:
        json.dump(vulnerabilities, f, indent=4)
